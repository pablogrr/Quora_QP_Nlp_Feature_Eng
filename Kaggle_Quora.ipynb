{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "import numpy as np\n",
    "from nltk import *\n",
    "import os\n",
    "import statistics\n",
    "import editdistance\n",
    "import itertools  \n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = pd.read_csv('quora_question_pairs/quora_train.csv')\n",
    "#train_df, test_df = sklearn.model_selection.train_test_split(full_train_df, test_size=0.1,random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all in string\n",
    "def cast_list_as_strings(mylist):\n",
    "    \"\"\"\n",
    "    return a list of strings\n",
    "    \"\"\"\n",
    "    #assert isinstance(mylist, list), f\"the input mylist should be a list it is {type(mylist)}\"\n",
    "    mylist_of_strings = []\n",
    "    for x in mylist:\n",
    "        mylist_of_strings.append(str(x))\n",
    "\n",
    "    return mylist_of_strings\n",
    "\n",
    "#Removing Stops Words\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    stops     = set(stopwords.words(\"english\"))\n",
    "    token_doc = set(word_tokenize(doc))\n",
    "    token_doc = list(token_doc - stops)\n",
    "    return \" \".join(token_doc)\n",
    "\n",
    "#Adding len Words in common feat\n",
    "def len_common(q1, q2):\n",
    "    q1 = set(word_tokenize(q1)) ; q2 = set(word_tokenize(q2))\n",
    "    return len(q1.intersection(q2))\n",
    "\n",
    "#Adding len common words in common feat\n",
    "def len_not_common(q1,q2):\n",
    "    q1 = set(word_tokenize(q1)) ; q2 = set(word_tokenize(q2))\n",
    "    return len(q1 ^ q2)\n",
    "\n",
    "#Adding mean distance between common words \n",
    "def mean_dist_not_com(q1,q2):\n",
    "    q1 = set(word_tokenize(q1)) ; q2 = set(word_tokenize(q2))\n",
    "    not_comm1 = (q1 ^ q2) - q1\n",
    "    if len(not_comm1)==0 : not_comm1={''}\n",
    "    not_comm2 = (q1 ^ q2) - q2\n",
    "    if len(not_comm2)==0 : not_comm2={''}\n",
    "    return statistics.mean([editdistance.eval(i[0],i[1]) for i in itertools.product(not_comm1, not_comm2)])\n",
    "\n",
    "def hasNumbers(inputString): return bool(re.search(r'\\d', inputString)) \n",
    "def both_number(q1,q2): return hasNumbers(q1) *  hasNumbers(q2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, scaler):\n",
    "    df = df.copy()\n",
    "    df['question1_string'] = cast_list_as_strings(list(df[\"question1\"]))\n",
    "    df['question2_string'] = cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    df['question1_no_stops'] = [remove_stopwords(quest) for quest in df[\"question1_string\"]]\n",
    "    df['question2_no_stops'] = [remove_stopwords(quest) for quest in df[\"question2_string\"]]\n",
    "    \n",
    "    df['len_q1'] = [len(s) for s in df['question1_string']] \n",
    "    df['len_q2'] = [len(s) for s in df['question2_string']]\n",
    "    df['len_q1'] = scaler.fit_transform(df[['len_q1']])\n",
    "    df['len_q2'] = scaler.fit_transform(df[['len_q2']])\n",
    "    \n",
    "    df['len_common'] = [len_common(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    df['len_common'] = scaler.fit_transform(df[['len_common']])\n",
    "\n",
    "    df['len_not_common'] = [len_not_common(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    df['len_not_common'] = scaler.fit_transform(df[['len_not_common']])\n",
    "    \n",
    "    df['mean_dist_not_com'] = [mean_dist_not_com(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    df['mean_dist_not_com'] = scaler.fit_transform(df[['mean_dist_not_com']])\n",
    "    \n",
    "    df['both_number'] = [both_number(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('data_preprocessed.csv')\n",
    "df_full = df_full.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW REPRESENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_on_q1_q2(df, model):\n",
    "    q_list1 = list(df[\"question1_string\"])\n",
    "    q_list2 = list(df[\"question2_string\"])\n",
    "    all_questions = q_list1 + q_list2 \n",
    "    model.fit(all_questions)\n",
    "    return\n",
    "\n",
    "def get_features_from_df(df, count_vectorizer):\n",
    "    \"\"\"\n",
    "    returns a sparse matrix containing the features build by the count vectorizer.\n",
    "    Each row should contain features from question1 and question2.\n",
    "    \"\"\"\n",
    "    q1_casted =  cast_list_as_strings(list(df[\"question1\"]))\n",
    "    q2_casted =  cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    ############### Begin exercise ###################\n",
    "    # what is kaggle                  q1\n",
    "    # What is the kaggle platform     q2\n",
    "    X_q1 = count_vectorizer.transform(q1_casted)\n",
    "    X_q2 = count_vectorizer.transform(q2_casted)    \n",
    "    X_q1q2 = scipy.sparse.hstack((X_q1,X_q2))\n",
    "    ############### End exercise ###################\n",
    "\n",
    "    return X_q1q2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",\n",
    "                                                       random_state=123)\n",
    "\n",
    "    \n",
    "    train_df, test_df = sklearn.model_selection.train_test_split(df_full, test_size=0.05,random_state=123)\n",
    "    train_df, val_df  = sklearn.model_selection.train_test_split(train_df, test_size=0.05,random_state=123)\n",
    "    X_train_q1q2      = get_features_from_df(train_df, count_vectorizer)\n",
    "    X_val_q1q2        = get_features_from_df(val_df, count_vectorizer)\n",
    "    X_test_q1q2       = get_features_from_df(test_df, count_vectorizer)\n",
    "    y_train           = train_df[\"is_duplicate\"].values\n",
    "    y_val             = val_df[\"is_duplicate\"].values\n",
    "    y_test            = test_df[\"is_duplicate\"].values\n",
    "    \n",
    "    logistic.fit(X_train_q1q2, y_train)\n",
    "\n",
    "                                                   \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablogranatiero/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:14:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:14:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, eta=0.3, gamma=0,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=50,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=80, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=123, reg_alpha=4,\n",
       "              reg_lambda=1, scale_pos_weight=1, silent=1, subsample=0.8,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train_q1q2, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25333562, 0.14860882, 0.42875916, ..., 0.39663774, 0.30302086,\n",
       "       0.07505125], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.predict_proba(X_train_q1q2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279273390519733"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, xgb_model.predict_proba(X_train_q1q2)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(df, get_feat_model, vectorizer_func):\n",
    "    \n",
    "    logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",\n",
    "                                                       random_state=123)\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, \n",
    "                              learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "                              objective='binary:logistic', eta=0.3, silent=1, subsample=0.8, random_state=123)\n",
    "\n",
    "    #svm_model = svm.SVC()\n",
    "    \n",
    "    train_df, test_df = sklearn.model_selection.train_test_split(df, test_size=0.05,random_state=123)\n",
    "    train_df, val_df  = sklearn.model_selection.train_test_split(train_df, test_size=0.05,random_state=123)\n",
    "    X_train_q1q2      = get_feat_model(train_df, vectorizer_func)\n",
    "    X_val_q1q2        = get_feat_model(val_df, vectorizer_func)\n",
    "    X_test_q1q2       = get_feat_model(test_df, vectorizer_func)\n",
    "    y_train           = train_df[\"is_duplicate\"].values\n",
    "    y_val             = val_df[\"is_duplicate\"].values\n",
    "    y_test            = test_df[\"is_duplicate\"].values\n",
    "    \n",
    "    logistic.fit(X_train_q1q2, y_train)\n",
    "    xgb_model.fit(X_train_q1q2, y_train) \n",
    "    #svm_model.fit(X_tr_q1q2, y_train)\n",
    "                                                   \n",
    "    logistic_train_acc = roc_auc_score(y_train, logistic.predict_proba(X_train_q1q2)[:, 1])                                                       \n",
    "    logistic_val_acc   = roc_auc_score(y_train, logistic.predict_proba(X_val_q1q2)[:, 1])\n",
    "    logistic_test_acc  = roc_auc_score(y_train, logistic.predict_proba(X_test_q1q2)[:, 1])\n",
    "    print('logistic_train_acc:{}, logistic_val_acc:{}, logistic_test_acc:{}'.format(logistic_train_acc, logistic_val_acc, logistic_test_acc))\n",
    "                                                   \n",
    "    xgb_train_acc      = roc_auc_score(y_train, xgb_model.predict_proba(X_train_q1q2)[:, 1])\n",
    "    xgb_val_acc        = roc_auc_score(y_val, xgb_model.predict_proba(X_val_q1q2)[:, 1])\n",
    "    xgb_test_acc       = roc_auc_score(y_test, xgb_model.predict_proba(X_test_q1q2)[:, 1])\n",
    "    print('xgb_train_acc:{}, xgb_val_acc:{}, xgb_test_acc:{}'.format(xgb_train_acc, xgb_val_acc, xgb_test_acc))\n",
    "                                                   \n",
    "    return [logistic_train_acc, logistic_val_acc, logistic_test_acc], [xgb_train_acc, xgb_val_acc, xgb_test_acc]\n",
    "                                                       \n",
    "                                                       \n",
    "                                                       \n",
    "                           \n",
    "                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1))\n",
    "\n",
    "fit_on_q1_q2(df_full, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_logistic, acc_xgboost = train_models(df_full, get_features_from_df, count_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF REPRESENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(df, tfidf, sim=False):\n",
    "    q1_casted =  cast_list_as_strings(list(df[\"question1\"]))\n",
    "    q2_casted =  cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    tfidf_q1 = tfidf.transform(q1_casted)\n",
    "    tfidf_q2 = tfidf.transform(q2_casted)\n",
    "    tfidf_q1q2 = scipy.sparse.hstack((tfidf_q1,tfidf_q2))\n",
    "    if sim == True:\n",
    "        sims = []\n",
    "        for i in range(len(q1_casted)):\n",
    "            sims.append(cosine_similarity(tfidf_q1[i,:],tfidf_q2[i,:]))\n",
    "        sims = np.reshape(sims, (len(q1_casted), 1))\n",
    "\n",
    "        return scipy.sparse.hstack((tfidf_q1q2,sims)).tocsr() \n",
    "    else:\n",
    "        return tfidf_q1q2.tocsr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "fit_on_q1_q2(df_full, tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablogranatiero/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:32:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:32:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logistic_train_acc:0.79214059014093, logistic_val_acc:0.7641116434076234, logistic_test_acc:0.765075439030423\n",
      "xgb_train_acc:0.8791637191229951, xgb_val_acc:0.7719671763079887, xgb_test_acc:0.7753559945880965\n"
     ]
    }
   ],
   "source": [
    "acc_logistic_tfidf, acc_xgboost_tfidf = train_models(df_full, get_tfidf, tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(df, tfidf, sim=True):\n",
    "    q1_casted =  cast_list_as_strings(list(df[\"question1\"]))\n",
    "    q2_casted =  cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    tfidf_q1 = tfidf.transform(q1_casted)\n",
    "    tfidf_q2 = tfidf.transform(q2_casted)\n",
    "    tfidf_q1q2 = scipy.sparse.hstack((tfidf_q1,tfidf_q2))\n",
    "    if sim == True:\n",
    "        sims = []\n",
    "        for i in range(len(q1_casted)):\n",
    "            sims.append(cosine_similarity(tfidf_q1[i,:],tfidf_q2[i,:]))\n",
    "        sims = np.reshape(sims, (len(q1_casted), 1))\n",
    "\n",
    "        return scipy.sparse.hstack((tfidf_q1q2,sims)).tocsr() \n",
    "    else:\n",
    "        return tfidf_q1q2.tocsr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablogranatiero/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:17:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:18:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logistic_train_acc:0.8256052973452976, logistic_val_acc:0.7962403665902937, logistic_test_acc:0.7995547860499629\n",
      "xgb_train_acc:0.9179797452089911, xgb_val_acc:0.8042715469580926, xgb_test_acc:0.8025583271975577\n"
     ]
    }
   ],
   "source": [
    "acc_logistic_tfidf_sim, acc_xgboost_tfidf_sim = train_models(df_full, get_tfidf, tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding features: len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_a_column_feat(df, col_list, sparse_matrix):\n",
    "\n",
    "    for col_q in col_list:\n",
    "        feat_q = df[col_q].to_numpy().reshape(len(df[col_q]),1)\n",
    "        sparse_matrix = scipy.sparse.hstack((sparse_matrix,feat_q)).tocsr()\n",
    "    \n",
    "    return sparse_matrix     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(df, get_feat_model, vectorizer_func, col_list):\n",
    "    \n",
    "    logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",\n",
    "                                                       random_state=123)\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, \n",
    "                              learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "                              objective='binary:logistic', eta=0.3, silent=1, subsample=0.8, random_state=123)\n",
    "\n",
    "    #svm_model = svm.SVC()\n",
    "    \n",
    "    train_df, test_df = sklearn.model_selection.train_test_split(df, test_size=0.05,random_state=123)\n",
    "    train_df, val_df  = sklearn.model_selection.train_test_split(train_df, test_size=0.05,random_state=123)\n",
    "    X_train_q1q2      = get_feat_model(train_df, vectorizer_func)\n",
    "    X_val_q1q2        = get_feat_model(val_df, vectorizer_func)\n",
    "    X_test_q1q2       = get_feat_model(test_df, vectorizer_func)\n",
    "    \n",
    "    X_train_q1q2      = add_a_column_feat_single(train_df, col_list, X_train_q1q2)\n",
    "    X_val_q1q2        = add_a_column_feat_single(val_df, col_list, X_val_q1q2)\n",
    "    X_test_q1q2       = add_a_column_feat_single(test_df, col_list, X_test_q1q2)\n",
    "    \n",
    "    y_train           = train_df[\"is_duplicate\"].values\n",
    "    y_val             = val_df[\"is_duplicate\"].values\n",
    "    y_test            = test_df[\"is_duplicate\"].values\n",
    "    \n",
    "    logistic.fit(X_train_q1q2, y_train)\n",
    "    xgb_model.fit(X_train_q1q2, y_train) \n",
    "    #svm_model.fit(X_tr_q1q2, y_train)\n",
    "                                                   \n",
    "    logistic_train_acc = roc_auc_score(y_train, logistic.predict_proba(X_train_q1q2)[:, 1])                                                       \n",
    "    logistic_val_acc   = roc_auc_score(y_train, logistic.predict_proba(X_val_q1q2)[:, 1])\n",
    "    logistic_test_acc  = roc_auc_score(y_train, logistic.predict_proba(X_test_q1q2)[:, 1])\n",
    "    print('logistic_train_acc:{}, logistic_val_acc:{}, logistic_test_acc:{}'.format(logistic_train_acc, logistic_val_acc, logistic_test_acc))\n",
    "                                                   \n",
    "    xgb_train_acc      = roc_auc_score(y_train, xgb_model.predict_proba(X_train_q1q2)[:, 1])\n",
    "    xgb_val_acc        = roc_auc_score(y_val, xgb_model.predict_proba(X_val_q1q2)[:, 1])\n",
    "    xgb_test_acc       = roc_auc_score(y_test, xgb_model.predict_proba(X_test_q1q2)[:, 1])\n",
    "    print('xgb_train_acc:{}, xgb_val_acc:{}, xgb_test_acc:{}'.format(xgb_train_acc, xgb_val_acc, xgb_test_acc))\n",
    "                                                   \n",
    "    return [logistic_train_acc, logistic_val_acc, logistic_test_acc], [xgb_train_acc, xgb_val_acc, xgb_test_acc]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablogranatiero/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:21:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:21:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logistic_train_acc:0.8261397459861537, logistic_val_acc:0.7966569464694855, logistic_test_acc:0.8002968093000248\n",
      "xgb_train_acc:0.9294939453594195, xgb_val_acc:0.8049364103873642, xgb_test_acc:0.8059043933919123\n"
     ]
    }
   ],
   "source": [
    "acc_logistic_tfidf_sim_len, acc_xgboost_tfidf_sim_len = train_models(df_full, get_tfidf, tfidf, ['len_q1', 'len_q2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding features: mean_dist_not_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablogranatiero/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:48:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:48:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logistic_train_acc:0.8266933799628353, logistic_val_acc:0.7978025411372631, logistic_test_acc:0.800939896116745\n",
      "xgb_train_acc:0.9339173567042016, xgb_val_acc:0.806458369095475, xgb_test_acc:0.8071895533827116\n"
     ]
    }
   ],
   "source": [
    "acc_logistic_mean_dist_not_com, acc_xgboost_mean_dist_not_com = train_models(df_full, get_tfidf, tfidf, ['len_q1', 'len_q2', 'mean_dist_not_com'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_logistic_mean_dist_not_com = [0.8266933799628353, 0.7978025411372631, 0.800939896116745]\n",
    "acc_xgboost_mean_dist_not_com =  [0.9339173567042016, 0.806458369095475, 0.8071895533827116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame({'BOW_No_Feat_Logistic':acc_logistic,'BOW_No_Feat_XGB':acc_xgboost,\n",
    "                     'TFIDF_No_Feat_Logistic':acc_logistic_tfidf,'TFIDF_No_Feat_XGB':acc_xgboost_tfidf,\n",
    "                     'TFIDF_Cos_Sim_Logistic':acc_logistic_tfidf_sim,'TFIDF_Cos_Sim_XGB':acc_xgboost_tfidf_sim,\n",
    "                     'TFIDF_Cos_Sim_Len_Logistic':acc_logistic_tfidf_sim_len,'TFIDF_Cos_Sim_Len_XGB':acc_xgboost_tfidf_sim_len,\n",
    "                     'TFIDF_Cos_Sim_Len_Logistic':acc_logistic_tfidf_sim_len,'TFIDF_Cos_Sim_Len_XGB':acc_xgboost_tfidf_sim_len,\n",
    "                     'TFIDF_mean_dist_not_com_Logistic':acc_logistic_mean_dist_not_com,'TFIDF_mean_dist_not_com_XGB':acc_xgboost_mean_dist_not_com,\n",
    "                    }, index=['Train','Validation', 'Test'])\n",
    "hist.to_csv('hist.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW_No_Feat_Logistic</th>\n",
       "      <th>BOW_No_Feat_XGB</th>\n",
       "      <th>TFIDF_No_Feat_Logistic</th>\n",
       "      <th>TFIDF_No_Feat_XGB</th>\n",
       "      <th>TFIDF_Cos_Sim_Logistic</th>\n",
       "      <th>TFIDF_Cos_Sim_XGB</th>\n",
       "      <th>TFIDF_Cos_Sim_Len_Logistic</th>\n",
       "      <th>TFIDF_Cos_Sim_Len_XGB</th>\n",
       "      <th>TFIDF_mean_dist_not_com_Logistic</th>\n",
       "      <th>TFIDF_mean_dist_not_com_XGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.821916</td>\n",
       "      <td>0.792141</td>\n",
       "      <td>0.879164</td>\n",
       "      <td>0.825605</td>\n",
       "      <td>0.917980</td>\n",
       "      <td>0.826140</td>\n",
       "      <td>0.929494</td>\n",
       "      <td>0.826693</td>\n",
       "      <td>0.933917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>0.754895</td>\n",
       "      <td>0.762478</td>\n",
       "      <td>0.764112</td>\n",
       "      <td>0.771967</td>\n",
       "      <td>0.796240</td>\n",
       "      <td>0.804272</td>\n",
       "      <td>0.796657</td>\n",
       "      <td>0.804936</td>\n",
       "      <td>0.797803</td>\n",
       "      <td>0.806458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.758595</td>\n",
       "      <td>0.766916</td>\n",
       "      <td>0.765075</td>\n",
       "      <td>0.775356</td>\n",
       "      <td>0.799555</td>\n",
       "      <td>0.802558</td>\n",
       "      <td>0.800297</td>\n",
       "      <td>0.805904</td>\n",
       "      <td>0.800940</td>\n",
       "      <td>0.807190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BOW_No_Feat_Logistic  BOW_No_Feat_XGB  TFIDF_No_Feat_Logistic  \\\n",
       "Train                   0.809158         0.821916                0.792141   \n",
       "Validation              0.754895         0.762478                0.764112   \n",
       "Test                    0.758595         0.766916                0.765075   \n",
       "\n",
       "            TFIDF_No_Feat_XGB  TFIDF_Cos_Sim_Logistic  TFIDF_Cos_Sim_XGB  \\\n",
       "Train                0.879164                0.825605           0.917980   \n",
       "Validation           0.771967                0.796240           0.804272   \n",
       "Test                 0.775356                0.799555           0.802558   \n",
       "\n",
       "            TFIDF_Cos_Sim_Len_Logistic  TFIDF_Cos_Sim_Len_XGB  \\\n",
       "Train                         0.826140               0.929494   \n",
       "Validation                    0.796657               0.804936   \n",
       "Test                          0.800297               0.805904   \n",
       "\n",
       "            TFIDF_mean_dist_not_com_Logistic  TFIDF_mean_dist_not_com_XGB  \n",
       "Train                               0.826693                     0.933917  \n",
       "Validation                          0.797803                     0.806458  \n",
       "Test                                0.800940                     0.807190  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
