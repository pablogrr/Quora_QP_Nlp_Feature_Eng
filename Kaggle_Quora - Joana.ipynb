{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "import numpy as np\n",
    "from nltk import *\n",
    "import os\n",
    "import statistics\n",
    "import editdistance\n",
    "import itertools  \n",
    "import re\n",
    "import random\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seet to generate reproducable results\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jsreu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsreu\\anaconda3\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3155: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "path_data =  os.path.expanduser('~') \n",
    "\n",
    "# use this to train and VALIDATE your solution\n",
    "full_train_df = pd.read_csv(os.path.join(path_data, os.path.join(\"Datasets\", \"kaggle_datasets\", \"quora\", \"quora_train_data.csv\")))\n",
    "\n",
    "# use this to provide the expected generalization results\n",
    "# test_df = pd.read_csv(\"../data/quora_test_data.csv\")\n",
    "test_data = pd.read_csv(os.path.join(path_data, os.path.join(\"Datasets\", \"kaggle_datasets\", \"quora\", \"quora_test_data.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all in string\n",
    "def cast_list_as_strings(mylist):\n",
    "    \"\"\"\n",
    "    return a list of strings\n",
    "    \"\"\"\n",
    "    #assert isinstance(mylist, list), f\"the input mylist should be a list it is {type(mylist)}\"\n",
    "    mylist_of_strings = []\n",
    "    for x in mylist:\n",
    "        mylist_of_strings.append(str(x))\n",
    "\n",
    "    return mylist_of_strings\n",
    "\n",
    "#Removing Stops Words\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    stops     = set(stopwords.words(\"english\"))\n",
    "    token_doc = set(word_tokenize(doc))\n",
    "    token_doc = list(token_doc - stops)\n",
    "    return \" \".join(token_doc)\n",
    "\n",
    "#Adding len Words in common feat\n",
    "def len_common(q1, q2):\n",
    "    q1 = set(word_tokenize(q1)) ; q2 = set(word_tokenize(q2))\n",
    "    return len(q1.intersection(q2))\n",
    "\n",
    "#Adding len common words in common feat\n",
    "def len_not_common(q1,q2):\n",
    "    q1 = set(word_tokenize(q1)) ; q2 = set(word_tokenize(q2))\n",
    "    return len(q1 ^ q2)\n",
    "\n",
    "#Adding mean distance between common words \n",
    "def mean_dist_not_com(q1,q2):\n",
    "    q1 = set(word_tokenize(q1)) ; q2 = set(word_tokenize(q2))\n",
    "    not_comm1 = (q1 ^ q2) - q1\n",
    "    if len(not_comm1)==0 : not_comm1={''}\n",
    "    not_comm2 = (q1 ^ q2) - q2\n",
    "    if len(not_comm2)==0 : not_comm2={''}\n",
    "    return statistics.mean([editdistance.eval(i[0],i[1]) for i in itertools.product(not_comm1, not_comm2)])\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString)) \n",
    "def both_number(q1,q2):\n",
    "    return hasNumbers(q1) *  hasNumbers(q2) \n",
    "\n",
    "# get average number of words\n",
    "def average_len(question):\n",
    "    num_words = len(question.split())\n",
    "    return len(question)/num_words   \n",
    "\n",
    "\n",
    "# levenshtein distance (for strings of unequal length)\n",
    "def levenshtein(q1, q2): \n",
    "    #create initial array (two for loops since q1 and q2 can differ in length)\n",
    "    dist_array = []\n",
    "    for i in range(len(q1)+1):\n",
    "        dist_array.append([0]*(len(q2)+1))\n",
    "        dist_array[i][0] = i\n",
    "    for j in range(len(q2)+1):\n",
    "        dist_array[0][j] = j\n",
    "\n",
    "    dist = [0]*3\n",
    "    for i in range(1,len(q1)+1):\n",
    "        for j in range(1,len(q2)+1):\n",
    "            dist[0] = dist_array[i-1][j-1] if q1[i-1]==q2[j-1] else dist_array[i-1][j-1]+1\n",
    "            dist[1] = dist_array[i][j-1]+1\n",
    "            dist[2] = dist_array[i-1][j]+1\n",
    "            dist_array[i][j]=min(dist)\n",
    "    \n",
    "    return dist_array[i][j]\n",
    "        \n",
    "\n",
    "\n",
    "# manhattan distance\n",
    "def manhattan(q1,q2):\n",
    "    return sum(abs(word1-word2) for word1, word2 in zip(q1,q2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self implemented jaccard similarity\n",
    "#from math import*\n",
    " \n",
    "def jaccard_similarity(vector1,vector2):\n",
    "    jacc_num = 0 \n",
    "    jacc_den = 0 \n",
    "    for index in enumerate(vector1): \n",
    "        if vector1[index] != 0 or vector2[index] != 0: \n",
    "            jacc_den += max(vector1[index], vector2[index]) \n",
    "            jacc_num += min(vector1[index], vector2[index]) \n",
    "    return jacc_num / jacc_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, scaler):\n",
    "    df = df.copy()\n",
    "    df['question1_string'] = cast_list_as_strings(list(df[\"question1\"]))\n",
    "    df['question2_string'] = cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    df['question1_no_stops'] = [remove_stopwords(quest) for quest in df[\"question1_string\"]]\n",
    "    df['question2_no_stops'] = [remove_stopwords(quest) for quest in df[\"question2_string\"]]\n",
    "    \n",
    "    df['len_q1'] = [len(s) for s in df['question1_string']] \n",
    "    df['len_q2'] = [len(s) for s in df['question2_string']]\n",
    "    df['len_q1'] = scaler.fit_transform(df[['len_q1']])\n",
    "    df['len_q2'] = scaler.fit_transform(df[['len_q2']])\n",
    "    \n",
    "    df['len_common'] = [len_common(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    df['len_common'] = scaler.fit_transform(df[['len_common']])\n",
    "\n",
    "    df['len_not_common'] = [len_not_common(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    df['len_not_common'] = scaler.fit_transform(df[['len_not_common']])\n",
    "    \n",
    "    df['mean_dist_not_com'] = [mean_dist_not_com(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    df['mean_dist_not_com'] = scaler.fit_transform(df[['mean_dist_not_com']])\n",
    "    \n",
    "    df['both_number'] = [both_number(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    \n",
    "    df[\"avg_len_q1\"]= df.question1_string.apply(lambda x: average_len(x))\n",
    "    df[\"avg_len_q2\"]= df.question2_string.apply(lambda x: average_len(x))\n",
    "    \n",
    "    df['edit_distance'] = [editdistance.eval(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    \n",
    "    df['levenshtein_distance'] = [levenshtein(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "    \n",
    "    df['manhattan_distance'] = [manhattan(df.loc[i,'question1_string'],df.loc[i,'question2_string']) for i in range(len(df))]\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "df_full = preprocess(full_train_df, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_full = pd.read_csv('data_preprocessed.csv')\n",
    "#df_full = df_full.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW REPRESENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_on_q1_q2(df, model):\n",
    "    q_list1 = list(df[\"question1_string\"])\n",
    "    q_list2 = list(df[\"question2_string\"])\n",
    "    all_questions = q_list1 + q_list2 \n",
    "    model.fit(all_questions)\n",
    "    return\n",
    "\n",
    "def get_features_from_df(df, count_vectorizer):\n",
    "    \"\"\"\n",
    "    returns a sparse matrix containing the features build by the count vectorizer.\n",
    "    Each row should contain features from question1 and question2.\n",
    "    \"\"\"\n",
    "    q1_casted =  cast_list_as_strings(list(df[\"question1\"]))\n",
    "    q2_casted =  cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    ############### Begin exercise ###################\n",
    "    # what is kaggle                  q1\n",
    "    # What is the kaggle platform     q2\n",
    "    X_q1 = count_vectorizer.transform(q1_casted)\n",
    "    X_q2 = count_vectorizer.transform(q2_casted)    \n",
    "    X_q1q2 = scipy.sparse.hstack((X_q1,X_q2))\n",
    "    ############### End exercise ###################\n",
    "\n",
    "    return X_q1q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(df, get_feat_model, vectorizer_func):\n",
    "    \n",
    "    logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",\n",
    "                                                       random_state=123)\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, \n",
    "                              learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "                              objective='binary:logistic', eta=0.3, silent=1, subsample=0.8, random_state=123)\n",
    "\n",
    "    #svm_model = svm.SVC()\n",
    "    \n",
    "    train_df, test_df = sklearn.model_selection.train_test_split(df, test_size=0.05,random_state=123)\n",
    "    train_df, val_df  = sklearn.model_selection.train_test_split(train_df, test_size=0.05,random_state=123)\n",
    "    X_train_q1q2      = get_feat_model(train_df, vectorizer_func)\n",
    "    X_val_q1q2        = get_feat_model(val_df, vectorizer_func)\n",
    "    X_test_q1q2       = get_feat_model(test_df, vectorizer_func)\n",
    "    y_train           = train_df[\"is_duplicate\"].values\n",
    "    y_val             = val_df[\"is_duplicate\"].values\n",
    "    y_test            = test_df[\"is_duplicate\"].values\n",
    "    \n",
    "    logistic.fit(X_train_q1q2, y_train)\n",
    "    xgb_model.fit(X_train_q1q2, y_train) \n",
    "    #svm_model.fit(X_tr_q1q2, y_train)\n",
    "                                                   \n",
    "    logistic_train_acc = roc_auc_score(y_train, logistic.predict_proba(X_train_q1q2)[:, 1])                                                       \n",
    "    logistic_val_acc   = roc_auc_score(y_val, logistic.predict_proba(X_val_q1q2)[:, 1])\n",
    "    logistic_test_acc  = roc_auc_score(y_test, logistic.predict_proba(X_test_q1q2)[:, 1])\n",
    "    print('logistic_train_acc:{}, logistic_val_acc:{}, logistic_test_acc:{}'.format(logistic_train_acc, logistic_val_acc, logistic_test_acc))\n",
    "                                                   \n",
    "    xgb_train_acc      = roc_auc_score(y_train, xgb_model.predict_proba(X_train_q1q2)[:, 1])\n",
    "    xgb_val_acc        = roc_auc_score(y_val, xgb_model.predict_proba(X_val_q1q2)[:, 1])\n",
    "    xgb_test_acc       = roc_auc_score(y_test, xgb_model.predict_proba(X_test_q1q2)[:, 1])\n",
    "    print('xgb_train_acc:{}, xgb_val_acc:{}, xgb_test_acc:{}'.format(xgb_train_acc, xgb_val_acc, xgb_test_acc))\n",
    "                                                   \n",
    "    return [logistic_train_acc, logistic_val_acc, logistic_test_acc], [xgb_train_acc, xgb_val_acc, xgb_test_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1))\n",
    "\n",
    "fit_on_q1_q2(df_full, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsreu\\anaconda3\\envs\\NLP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:07:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:07:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logistic_train_acc:0.8855901648010354, logistic_val_acc:0.8058405123003487, logistic_test_acc:0.8114412532189331\n",
      "xgb_train_acc:0.9285486235026952, xgb_val_acc:0.8666926609936174, xgb_test_acc:0.8704437920508217\n"
     ]
    }
   ],
   "source": [
    "AUC_logistic, AUC_xgboost = train_models(df_full, get_features_from_df, count_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF REPRESENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(df, tfidf, sim=False):\n",
    "    q1_casted =  cast_list_as_strings(list(df[\"question1\"]))\n",
    "    q2_casted =  cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    tfidf_q1 = tfidf.transform(q1_casted)\n",
    "    tfidf_q2 = tfidf.transform(q2_casted)\n",
    "    tfidf_q1q2 = scipy.sparse.hstack((tfidf_q1,tfidf_q2))\n",
    "    if sim == True:\n",
    "        sims = []\n",
    "        for i in range(len(q1_casted)):\n",
    "            sims.append(cosine_similarity(tfidf_q1[i,:],tfidf_q2[i,:]))\n",
    "        sims = np.reshape(sims, (len(q1_casted), 1))\n",
    "\n",
    "        return scipy.sparse.hstack((tfidf_q1q2,sims)).tocsr() \n",
    "    else:\n",
    "        return tfidf_q1q2.tocsr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "fit_on_q1_q2(df_full, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsreu\\anaconda3\\envs\\NLP\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:39:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:39:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logistic_train_acc:0.8635705585260952, logistic_val_acc:0.8048111453905291, logistic_test_acc:0.8109112966502584\n",
      "xgb_train_acc:0.9640572026574558, xgb_val_acc:0.8694400593226587, xgb_test_acc:0.874641072242469\n"
     ]
    }
   ],
   "source": [
    "acc_logistic_tfidf, acc_xgboost_tfidf = train_models(df_full, get_tfidf, tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_sim(df, tfidf, sim=True):\n",
    "    q1_casted =  cast_list_as_strings(list(df[\"question1\"]))\n",
    "    q2_casted =  cast_list_as_strings(list(df[\"question2\"]))\n",
    "    \n",
    "    tfidf_q1 = tfidf.transform(q1_casted)\n",
    "    tfidf_q2 = tfidf.transform(q2_casted)\n",
    "    tfidf_q1q2 = scipy.sparse.hstack((tfidf_q1,tfidf_q2))\n",
    "    if sim == True:\n",
    "        sims = []\n",
    "        for i in range(len(q1_casted)):\n",
    "            sims.append(cosine_similarity(tfidf_q1[i,:],tfidf_q2[i,:]))\n",
    "        sims = np.reshape(sims, (len(q1_casted), 1))\n",
    "\n",
    "        return scipy.sparse.hstack((tfidf_q1q2,sims)).tocsr() \n",
    "    else:\n",
    "        return tfidf_q1q2.tocsr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_logistic_tfidf_sim, acc_xgboost_tfidf_sim = train_models(df_full, get_tfidf_sim, tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding features: len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_a_column_feat_single(df, col_list, sparse_matrix):\n",
    "\n",
    "    for col_q in col_list:\n",
    "        feat_q = df[col_q].to_numpy().reshape(len(df[col_q]),1)\n",
    "        sparse_matrix = scipy.sparse.hstack((sparse_matrix,feat_q)).tocsr()\n",
    "    \n",
    "    return sparse_matrix     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(df, get_feat_model, vectorizer_func, col_list):\n",
    "    \n",
    "    logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",\n",
    "                                                       random_state=123)\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(max_depth=50, n_estimators=80, \n",
    "                              learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "                              objective='binary:logistic', eta=0.3, silent=1, subsample=0.8, random_state=123)\n",
    "\n",
    "    #svm_model = svm.SVC()\n",
    "    \n",
    "    train_df, test_df = sklearn.model_selection.train_test_split(df, test_size=0.05,random_state=123)\n",
    "    train_df, val_df  = sklearn.model_selection.train_test_split(train_df, test_size=0.05,random_state=123)\n",
    "    X_train_q1q2      = get_feat_model(train_df, vectorizer_func)\n",
    "    X_val_q1q2        = get_feat_model(val_df, vectorizer_func)\n",
    "    X_test_q1q2       = get_feat_model(test_df, vectorizer_func)\n",
    "    \n",
    "    X_train_q1q2      = add_a_column_feat_single(train_df, col_list, X_train_q1q2)\n",
    "    X_val_q1q2        = add_a_column_feat_single(val_df, col_list, X_val_q1q2)\n",
    "    X_test_q1q2       = add_a_column_feat_single(test_df, col_list, X_test_q1q2)\n",
    "    \n",
    "    y_train           = train_df[\"is_duplicate\"].values\n",
    "    y_val             = val_df[\"is_duplicate\"].values\n",
    "    y_test            = test_df[\"is_duplicate\"].values\n",
    "    \n",
    "    logistic.fit(X_train_q1q2, y_train)\n",
    "    xgb_model.fit(X_train_q1q2, y_train) \n",
    "    #svm_model.fit(X_tr_q1q2, y_train)\n",
    "                                                   \n",
    "    logistic_train_acc = logistic.score(X_train_q1q2, y_train)                                                       \n",
    "    logistic_val_acc   = logistic.score(X_val_q1q2, y_val)\n",
    "    logistic_test_acc  = logistic.score(X_test_q1q2, y_test)\n",
    "    print('logistic_train_acc:{}, logistic_val_acc:{}, logistic_test_acc:{}'.format(logistic_train_acc, logistic_val_acc, logistic_test_acc))\n",
    "                                                   \n",
    "    xgb_train_acc      = f1_score(y_train, xgb_model.predict(X_train_q1q2), average='macro')\n",
    "    xgb_val_acc        = f1_score(y_val, xgb_model.predict(X_val_q1q2), average='macro')\n",
    "    xgb_test_acc       = f1_score(y_test, xgb_model.predict(X_test_q1q2), average='macro')\n",
    "    print('xgb_train_acc:{}, xgb_val_acc:{}, xgb_test_acc:{}'.format(xgb_train_acc, xgb_val_acc, xgb_test_acc))\n",
    "                                                   \n",
    "    return [logistic_train_acc, logistic_val_acc, logistic_test_acc], [xgb_train_acc, xgb_val_acc, xgb_test_acc]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablogranatiero/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:21:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:21:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logistic_train_acc:0.8261397459861537, logistic_val_acc:0.7966569464694855, logistic_test_acc:0.8002968093000248\n",
      "xgb_train_acc:0.9294939453594195, xgb_val_acc:0.8049364103873642, xgb_test_acc:0.8059043933919123\n"
     ]
    }
   ],
   "source": [
    "acc_logistic_tfidf_sim_len, acc_xgboost_tfidf_sim_len = train_models(df_full, get_tfidf, tfidf, ['len_q1', 'len_q2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding features: mean_dist_not_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablogranatiero/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:48:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:48:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logistic_train_acc:0.8266933799628353, logistic_val_acc:0.7978025411372631, logistic_test_acc:0.800939896116745\n",
      "xgb_train_acc:0.9339173567042016, xgb_val_acc:0.806458369095475, xgb_test_acc:0.8071895533827116\n"
     ]
    }
   ],
   "source": [
    "acc_logistic_mean_dist_not_com, acc_xgboost_mean_dist_not_com = train_models(df_full, get_tfidf, tfidf, ['len_q1', 'len_q2', 'mean_dist_not_com'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_logistic_mean_dist_not_com = [0.8266933799628353, 0.7978025411372631, 0.800939896116745]\n",
    "acc_xgboost_mean_dist_not_com = [0.9339173567042016, 0.806458369095475, 0.8071895533827116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame({'BOW_No_Feat_Logistic':acc_logistic,'BOW_No_Feat_XGB':acc_xgboost,\n",
    "                     'TFIDF_No_Feat_Logistic':acc_logistic_tfidf,'TFIDF_No_Feat_XGB':acc_xgboost_tfidf,\n",
    "                     'TFIDF_Cos_Sim_Logistic':acc_logistic_tfidf_sim,'TFIDF_Cos_Sim_XGB':acc_xgboost_tfidf_sim,\n",
    "                     'TFIDF_Cos_Sim_Len_Logistic':acc_logistic_tfidf_sim_len,'TFIDF_Cos_Sim_Len_XGB':acc_xgboost_tfidf_sim_len,\n",
    "                     'TFIDF_Cos_Sim_Len_Logistic':acc_logistic_tfidf_sim_len,'TFIDF_Cos_Sim_Len_XGB':acc_xgboost_tfidf_sim_len,\n",
    "                     'TFIDF_mean_dist_not_com_Logistic':acc_logistic_mean_dist_not_com,'TFIDF_mean_dist_not_com_XGB':acc_xgboost_mean_dist_not_com,\n",
    "                    }, index=['Train','Validation', 'Test'])\n",
    "hist.to_csv('hist.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW_No_Feat_Logistic</th>\n",
       "      <th>BOW_No_Feat_XGB</th>\n",
       "      <th>TFIDF_No_Feat_Logistic</th>\n",
       "      <th>TFIDF_No_Feat_XGB</th>\n",
       "      <th>TFIDF_Cos_Sim_Logistic</th>\n",
       "      <th>TFIDF_Cos_Sim_XGB</th>\n",
       "      <th>TFIDF_Cos_Sim_Len_Logistic</th>\n",
       "      <th>TFIDF_Cos_Sim_Len_XGB</th>\n",
       "      <th>TFIDF_mean_dist_not_com_Logistic</th>\n",
       "      <th>TFIDF_mean_dist_not_com_XGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.821916</td>\n",
       "      <td>0.792141</td>\n",
       "      <td>0.879164</td>\n",
       "      <td>0.825605</td>\n",
       "      <td>0.917980</td>\n",
       "      <td>0.826140</td>\n",
       "      <td>0.929494</td>\n",
       "      <td>0.826693</td>\n",
       "      <td>0.933917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>0.754895</td>\n",
       "      <td>0.762478</td>\n",
       "      <td>0.764112</td>\n",
       "      <td>0.771967</td>\n",
       "      <td>0.796240</td>\n",
       "      <td>0.804272</td>\n",
       "      <td>0.796657</td>\n",
       "      <td>0.804936</td>\n",
       "      <td>0.797803</td>\n",
       "      <td>0.806458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.758595</td>\n",
       "      <td>0.766916</td>\n",
       "      <td>0.765075</td>\n",
       "      <td>0.775356</td>\n",
       "      <td>0.799555</td>\n",
       "      <td>0.802558</td>\n",
       "      <td>0.800297</td>\n",
       "      <td>0.805904</td>\n",
       "      <td>0.800940</td>\n",
       "      <td>0.807190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BOW_No_Feat_Logistic  BOW_No_Feat_XGB  TFIDF_No_Feat_Logistic  \\\n",
       "Train                   0.809158         0.821916                0.792141   \n",
       "Validation              0.754895         0.762478                0.764112   \n",
       "Test                    0.758595         0.766916                0.765075   \n",
       "\n",
       "            TFIDF_No_Feat_XGB  TFIDF_Cos_Sim_Logistic  TFIDF_Cos_Sim_XGB  \\\n",
       "Train                0.879164                0.825605           0.917980   \n",
       "Validation           0.771967                0.796240           0.804272   \n",
       "Test                 0.775356                0.799555           0.802558   \n",
       "\n",
       "            TFIDF_Cos_Sim_Len_Logistic  TFIDF_Cos_Sim_Len_XGB  \\\n",
       "Train                         0.826140               0.929494   \n",
       "Validation                    0.796657               0.804936   \n",
       "Test                          0.800297               0.805904   \n",
       "\n",
       "            TFIDF_mean_dist_not_com_Logistic  TFIDF_mean_dist_not_com_XGB  \n",
       "Train                               0.826693                     0.933917  \n",
       "Validation                          0.797803                     0.806458  \n",
       "Test                                0.800940                     0.807190  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
